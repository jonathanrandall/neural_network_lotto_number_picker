{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## makemore: babynames lotto tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "myseed=round(time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['37,28,27,11,41,23,2,1',\n",
       " '11,9,14,29,7,15,17,23',\n",
       " '9,37,32,41,40,16,28,30',\n",
       " '6,10,18,32,33,37,21,23',\n",
       " '14,16,24,34,41,44,21,30',\n",
       " '5,10,30,32,34,42,19,45',\n",
       " '1,2,18,24,36,43,9,31',\n",
       " '3,14,32,37,42,45,17,20']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('sat_lotto.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "820"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for w in words:\n",
    "    results.append([int(num) for num in w.strip().split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[37, 28, 27, 11, 41, 23, 2, 1],\n",
       " [11, 9, 14, 29, 7, 15, 17, 23],\n",
       " [9, 37, 32, 41, 40, 16, 28, 30],\n",
       " [6, 10, 18, 32, 33, 37, 21, 23],\n",
       " [14, 16, 24, 34, 41, 44, 21, 30],\n",
       " [5, 10, 30, 32, 34, 42, 19, 45],\n",
       " [1, 2, 18, 24, 36, 43, 9, 31],\n",
       " [3, 14, 32, 37, 42, 45, 17, 20]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38, 39: 39, 40: 40, 41: 41, 42: 42, 43: 43, 44: 44, 45: 45}\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(range(0,46))))\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "# stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(stoi)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5248, 3]) torch.Size([5248])\n",
      "torch.Size([656, 3]) torch.Size([656])\n",
      "torch.Size([656, 3]) torch.Size([656])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "#abigail a b i, g\n",
    "\n",
    "def build_dataset(words):  \n",
    "    block_size = 3\n",
    "    X,Y = [], []\n",
    "    for w in words:\n",
    "#         print(w)\n",
    "        context = [0]*block_size\n",
    "        for ch in w :\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "        \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(results)\n",
    "n1 = int(0.8*len(results))\n",
    "n2 = int(0.9*len(results))\n",
    "\n",
    "Xtr, Ytr = build_dataset(results[:n1])\n",
    "Xdev, Ydev = build_dataset(results[n1:n2])\n",
    "Xte, Yte = build_dataset(results[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0] --> 4\n",
      "[0, 0, 4] --> 10\n",
      "[0, 4, 10] --> 17\n",
      "[4, 10, 17] --> 27\n",
      "[10, 17, 27] --> 34\n",
      "[17, 27, 34] --> 43\n",
      "[27, 34, 43] --> 18\n",
      "[34, 43, 18] --> 26\n",
      "[0, 0, 0] --> 3\n",
      "[0, 0, 3] --> 13\n",
      "[0, 3, 13] --> 17\n",
      "[3, 13, 17] --> 32\n",
      "[13, 17, 32] --> 38\n",
      "[17, 32, 38] --> 44\n",
      "[32, 38, 44] --> 43\n",
      "[38, 44, 43] --> 45\n",
      "[0, 0, 0] --> 20\n",
      "[0, 0, 20] --> 21\n",
      "[0, 20, 21] --> 31\n",
      "[20, 21, 31] --> 32\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "    print([itos[ix.item()] for ix in x], '-->', itos[y.item()])\n",
    "#   print([itos[ix.item()] for ix in x]), '-->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(myseed+46); # seed rng for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 16)             736       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               12544     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 46)                5934      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,134\n",
      "Trainable params: 52,622\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, BatchNormalization, Dropout\n",
    "embedding_dim=16\n",
    "max_sequence_length=block_size\n",
    "h1 = 256\n",
    "h2 = 128\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    # Embedding Layer\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length),\n",
    "    \n",
    "    # Flatten the embedded sequences (or you can use GlobalAveragePooling1D, GlobalMaxPooling1D, etc.)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Fully Connected Neural Network (Dense Layer)\n",
    "    Dense(units=h1, activation='relu'),\n",
    "    \n",
    "    # Batch Normalization\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # Dropout for regularization\n",
    "    Dropout(0.5),  # Adjust the dropout rate as needed\n",
    "    \n",
    "    # Another Fully Connected Neural Network (Dense Layer)\n",
    "    Dense(units=h2, activation='relu'),\n",
    "    \n",
    "    Dropout(0.5),  # Adjust the dropout rate as needed\n",
    "    \n",
    "    # Output Layer (depending on your problem)\n",
    "    Dense(units=vocab_size, activation='softmax')  # Adjust the activation function for your problem\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "164/164 [==============================] - 1s 3ms/step - loss: 3.7629 - accuracy: 0.0373\n",
      "Epoch 2/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 3.5497 - accuracy: 0.0570\n",
      "Epoch 3/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 3.3829 - accuracy: 0.0739\n",
      "Epoch 4/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 3.3306 - accuracy: 0.0817\n",
      "Epoch 5/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 3.2726 - accuracy: 0.0777\n",
      "Epoch 6/10\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 3.2440 - accuracy: 0.0938\n",
      "Epoch 7/10\n",
      "164/164 [==============================] - 1s 3ms/step - loss: 3.2286 - accuracy: 0.1016\n",
      "Epoch 8/10\n",
      "164/164 [==============================] - 1s 5ms/step - loss: 3.1977 - accuracy: 0.1027\n",
      "Epoch 9/10\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 3.1812 - accuracy: 0.1067\n",
      "Epoch 10/10\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 3.1653 - accuracy: 0.1004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2102137efa0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtr.numpy(),Ytr.numpy(), epochs = 10, batch_size = 32, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 4s 15ms/step - loss: 2.9523 - accuracy: 0.1652\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Xtr.numpy(),Ytr.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 9ms/step - loss: 3.1479 - accuracy: 0.0854\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Xdev.numpy(), Ydev.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 11ms/step - loss: 3.2033 - accuracy: 0.0884\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Xte.numpy(), Yte.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.828641396489095"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "-math.log(1/46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 16, 26, 29, 37, 17]\n",
      "[2, 3, 8, 34, 36, 39]\n",
      "[2, 11, 14, 19, 22, 30]\n",
      "[5, 10, 15, 24, 34, 35]\n",
      "[3, 6, 10, 13, 18, 19]\n",
      "[11, 12, 21, 45, 7, 37]\n",
      "[2, 36, 41, 45, 34, 20]\n",
      "[1, 6, 11, 29, 40, 43]\n",
      "[4, 14, 18, 22, 43, 42]\n",
      "[1, 6, 9, 39, 11, 30]\n",
      "[15, 13, 37, 38, 4, 24]\n",
      "[17, 28, 34, 36, 4, 25]\n",
      "[1, 12, 31, 40, 44, 13]\n",
      "[1, 16, 25, 32, 34, 40]\n",
      "[2, 5, 16, 31, 38, 23]\n",
      "[1, 2, 19, 20, 25, 28]\n",
      "[6, 11, 23, 32, 39, 45]\n",
      "[2, 26, 31, 36, 35, 44]\n",
      "[23, 28, 10, 41, 11, 38]\n",
      "[5, 32, 41, 7, 8, 34]\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "# import tensorflow as tf\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "import numpy as np\n",
    "\n",
    "g = torch.Generator().manual_seed(myseed+12)#2147483647 + 12)\n",
    "start = []\n",
    "\n",
    "for i in range(20):\n",
    "\n",
    "    out = []    \n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    \n",
    "    #context = [np.random.randint(1, 46)] * block_size # initialize with all ...\n",
    "    #out = context\n",
    "    while True:\n",
    "        probs = model.predict([context],verbose=0);\n",
    "        probs = torch.from_numpy(probs)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        # shift the context window and track the samples\n",
    "        context = context[1:] + [ix]\n",
    "        if (not ix in out):\n",
    "            out.append(ix)\n",
    "        if len(out) == 6: #do until .\n",
    "            break\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
